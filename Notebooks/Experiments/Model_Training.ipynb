{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42a236e7-d372-4dba-b263-2b9232004c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.13.0-cp39-cp39-manylinux1_x86_64.whl (890.2 MB)\n",
      "\u001b[K     |████████████▍                   | 345.7 MB 104.4 MB/s eta 0:00:06"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |█████████████████████████▌      | 710.5 MB 132.6 MB/s eta 0:00:02"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 890.2 MB 8.5 kB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading torchvision-0.14.0-cp39-cp39-manylinux1_x86_64.whl (24.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.3 MB 75.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[K     |████████████████▏               | 282.1 MB 134.4 MB/s eta 0:00:03   |█▊                              | 30.5 MB 35.1 MB/s eta 0:00:15"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |███████████████████████████████▎| 545.4 MB 106.6 MB/s eta 0:00:01"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 557.1 MB 8.5 kB/s \n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[K     |███████████████████████████▉    | 276.1 MB 109.5 MB/s eta 0:00:01"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 317.1 MB 30 kB/s \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in ./.conda/envs/default/lib/python3.9/site-packages (from torch) (4.4.0)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[K     |████████████████████████████████| 849 kB 85.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 21.0 MB 97.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in ./.conda/envs/default/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (65.5.1)\n",
      "Requirement already satisfied: wheel in ./.conda/envs/default/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
      "Collecting pillow!=8.3.*,>=5.3.0\n",
      "  Downloading Pillow-9.3.0-cp39-cp39-manylinux_2_28_x86_64.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 100.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests\n",
      "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "\u001b[K     |████████████████████████████████| 62 kB 3.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting numpy\n",
      "  Downloading numpy-1.23.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 17.1 MB 95.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
      "\u001b[K     |████████████████████████████████| 140 kB 66.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting charset-normalizer<3,>=2\n",
      "  Downloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.conda/envs/default/lib/python3.9/site-packages (from requests->torchvision) (3.4)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2022.9.24-py3-none-any.whl (161 kB)\n",
      "\u001b[K     |████████████████████████████████| 161 kB 68.3 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: nvidia-cublas-cu11, urllib3, nvidia-cudnn-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, charset-normalizer, certifi, torch, requests, pillow, numpy, torchvision\n",
      "Successfully installed certifi-2022.9.24 charset-normalizer-2.1.1 numpy-1.23.5 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 pillow-9.3.0 requests-2.28.1 torch-1.13.0 torchvision-0.14.0 urllib3-1.26.12\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "395b0240-64c2-4c22-9dba-cdeee092ffec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.6.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.8 MB 9.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.0.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (296 kB)\n",
      "\u001b[K     |████████████████████████████████| 296 kB 97.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pillow>=6.2.0 in ./.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (9.3.0)\n",
      "Requirement already satisfied: numpy>=1.19 in ./.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (1.23.5)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
      "\u001b[K     |████████████████████████████████| 965 kB 111.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in ./.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in ./.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (3.0.9)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.4-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 103.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in ./.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./.conda/envs/default/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Installing collected packages: kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.0.6 cycler-0.11.0 fonttools-4.38.0 kiwisolver-1.4.4 matplotlib-3.6.2\n"
     ]
    }
   ],
   "source": [
    "!pip3 install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b97e282-af72-4e10-af48-407c9c2e5755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-1.5.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.2 MB 8.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pytz>=2020.1\n",
      "  Downloading pytz-2022.6-py2.py3-none-any.whl (498 kB)\n",
      "\u001b[K     |████████████████████████████████| 498 kB 118.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.20.3 in ./.conda/envs/default/lib/python3.9/site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./.conda/envs/default/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.conda/envs/default/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, pandas\n",
      "Successfully installed pandas-1.5.1 pytz-2022.6\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24b13a2b-3c99-4f19-8c7f-867bdaa14517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch-summary\n",
      "  Downloading torch_summary-1.4.5-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: torch-summary\n",
      "Successfully installed torch-summary-1.4.5\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch-summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3259d544-50b2-43bc-8aa4-e00adde97302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from torch.optim.optimizer import Optimizer\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0d59fbd-5a92-4c14-b072-58234e3dda35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cutout(object):\n",
    "    \"\"\"Randomly mask out one or more patches from an image.\n",
    "\n",
    "    Args:\n",
    "        n_holes (int): Number of patches to cut out of each image.\n",
    "        length (int): The length (in pixels) of each square patch.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_holes, length):\n",
    "        self.n_holes = n_holes\n",
    "        self.length = length\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (Tensor): Tensor image of size (C, H, W).\n",
    "        Returns:\n",
    "            Tensor: Image with n_holes of dimension length x length cut out of it.\n",
    "        \"\"\"\n",
    "        h = img.size(1)\n",
    "        w = img.size(2)\n",
    "\n",
    "        mask = np.ones((h, w), np.float32)\n",
    "\n",
    "        for n in range(self.n_holes):\n",
    "            y = np.random.randint(h)\n",
    "            x = np.random.randint(w)\n",
    "\n",
    "            y1 = np.clip(y - self.length // 2, 0, h)\n",
    "            y2 = np.clip(y + self.length // 2, 0, h)\n",
    "            x1 = np.clip(x - self.length // 2, 0, w)\n",
    "            x2 = np.clip(x + self.length // 2, 0, w)\n",
    "\n",
    "            mask[y1: y2, x1: x2] = 0.\n",
    "\n",
    "        mask = torch.from_numpy(mask)\n",
    "        mask = mask.expand_as(img)\n",
    "        img = img * mask\n",
    "\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0ca7944-16af-4999-b9db-e79bbc70fe5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class Lookahead(Optimizer):\n",
    "    r\"\"\"PyTorch implementation of the lookahead wrapper.\n",
    "\n",
    "    Lookahead Optimizer: https://arxiv.org/abs/1907.08610\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, optimizer, la_steps=5, la_alpha=0.8, pullback_momentum=\"none\"):\n",
    "        \"\"\"optimizer: inner optimizer\n",
    "        la_steps (int): number of lookahead steps\n",
    "        la_alpha (float): linear interpolation factor. 1.0 recovers the inner optimizer.\n",
    "        pullback_momentum (str): change to inner optimizer momentum on interpolation update\n",
    "        \"\"\"\n",
    "        self.optimizer = optimizer\n",
    "        self._la_step = 0  # counter for inner optimizer\n",
    "        self.la_alpha = la_alpha\n",
    "        self._total_la_steps = la_steps\n",
    "        pullback_momentum = pullback_momentum.lower()\n",
    "        assert pullback_momentum in [\"reset\", \"pullback\", \"none\"]\n",
    "        self.pullback_momentum = pullback_momentum\n",
    "\n",
    "        self.state = defaultdict(dict)\n",
    "\n",
    "        # Cache the current optimizer parameters\n",
    "        for group in optimizer.param_groups:\n",
    "            for p in group['params']:\n",
    "                param_state = self.state[p]\n",
    "                param_state['cached_params'] = torch.zeros_like(p.data)\n",
    "                param_state['cached_params'].copy_(p.data)\n",
    "                if self.pullback_momentum == \"pullback\":\n",
    "                    param_state['cached_mom'] = torch.zeros_like(p.data)\n",
    "\n",
    "    def __getstate__(self):\n",
    "        return {\n",
    "            'state': self.state,\n",
    "            'optimizer': self.optimizer,\n",
    "            'la_alpha': self.la_alpha,\n",
    "            '_la_step': self._la_step,\n",
    "            '_total_la_steps': self._total_la_steps,\n",
    "            'pullback_momentum': self.pullback_momentum\n",
    "        }\n",
    "\n",
    "    def zero_grad(self):\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "    def get_la_step(self):\n",
    "        return self._la_step\n",
    "\n",
    "    def state_dict(self):\n",
    "        return self.optimizer.state_dict()\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        self.optimizer.load_state_dict(state_dict)\n",
    "\n",
    "    def _backup_and_load_cache(self):\n",
    "        \"\"\"Useful for performing evaluation on the slow weights (which typically generalize better)\n",
    "        \"\"\"\n",
    "        for group in self.optimizer.param_groups:\n",
    "            for p in group['params']:\n",
    "                param_state = self.state[p]\n",
    "                param_state['backup_params'] = torch.zeros_like(p.data)\n",
    "                param_state['backup_params'].copy_(p.data)\n",
    "                p.data.copy_(param_state['cached_params'])\n",
    "\n",
    "    def _clear_and_load_backup(self):\n",
    "        for group in self.optimizer.param_groups:\n",
    "            for p in group['params']:\n",
    "                param_state = self.state[p]\n",
    "                p.data.copy_(param_state['backup_params'])\n",
    "                del param_state['backup_params']\n",
    "\n",
    "    @property\n",
    "    def param_groups(self):\n",
    "        return self.optimizer.param_groups\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        \"\"\"Performs a single Lookahead optimization step.\n",
    "        Arguments:\n",
    "            closure (callable, optional): A closure that reevaluates the model\n",
    "                and returns the loss.\n",
    "        \"\"\"\n",
    "        loss = self.optimizer.step(closure)\n",
    "        self._la_step += 1\n",
    "\n",
    "        if self._la_step >= self._total_la_steps:\n",
    "            self._la_step = 0\n",
    "            # Lookahead and cache the current optimizer parameters\n",
    "            for group in self.optimizer.param_groups:\n",
    "                for p in group['params']:\n",
    "                    param_state = self.state[p]\n",
    "                    p.data.mul_(self.la_alpha).add_(param_state['cached_params'], alpha=1.0 - self.la_alpha)  # crucial line\n",
    "                    param_state['cached_params'].copy_(p.data)\n",
    "                    if self.pullback_momentum == \"pullback\":\n",
    "                        internal_momentum = self.optimizer.state[p][\"momentum_buffer\"]\n",
    "                        self.optimizer.state[p][\"momentum_buffer\"] = internal_momentum.mul_(self.la_alpha).add_(\n",
    "                            1.0 - self.la_alpha, param_state[\"cached_mom\"])\n",
    "                        param_state[\"cached_mom\"] = self.optimizer.state[p][\"momentum_buffer\"]\n",
    "                    elif self.pullback_momentum == \"reset\":\n",
    "                        self.optimizer.state[p][\"momentum_buffer\"] = torch.zeros_like(p.data)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d55c5d8-12c2-4d2e-b076-c10fea214e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76d23d25-bb6d-4db1-bd8f-130bac57cbce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71553e89-e79a-4378-bfdb-bf70f6d83bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes,\n",
    "                          kernel_size=kernel_size, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512, num_classes)\n",
    "  \n",
    "  \n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        downsample = None\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, pool_size)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12f1b4cf-4d79-472e-8408-0f2efe1e5f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Conv2d: 1-1                            1,728\n",
      "├─BatchNorm2d: 1-2                       128\n",
      "├─Sequential: 1-3                        --\n",
      "|    └─BasicBlock: 2-1                   --\n",
      "|    |    └─Conv2d: 3-1                  36,864\n",
      "|    |    └─BatchNorm2d: 3-2             128\n",
      "|    |    └─Conv2d: 3-3                  36,864\n",
      "|    |    └─BatchNorm2d: 3-4             128\n",
      "|    |    └─Sequential: 3-5              --\n",
      "├─Sequential: 1-4                        --\n",
      "|    └─BasicBlock: 2-2                   --\n",
      "|    |    └─Conv2d: 3-6                  73,728\n",
      "|    |    └─BatchNorm2d: 3-7             256\n",
      "|    |    └─Conv2d: 3-8                  147,456\n",
      "|    |    └─BatchNorm2d: 3-9             256\n",
      "|    |    └─Sequential: 3-10             8,448\n",
      "├─Sequential: 1-5                        --\n",
      "|    └─BasicBlock: 2-3                   --\n",
      "|    |    └─Conv2d: 3-11                 294,912\n",
      "|    |    └─BatchNorm2d: 3-12            512\n",
      "|    |    └─Conv2d: 3-13                 589,824\n",
      "|    |    └─BatchNorm2d: 3-14            512\n",
      "|    |    └─Sequential: 3-15             33,280\n",
      "├─Sequential: 1-6                        --\n",
      "|    └─BasicBlock: 2-4                   --\n",
      "|    |    └─Conv2d: 3-16                 1,179,648\n",
      "|    |    └─BatchNorm2d: 3-17            1,024\n",
      "|    |    └─Conv2d: 3-18                 2,359,296\n",
      "|    |    └─BatchNorm2d: 3-19            1,024\n",
      "|    |    └─Sequential: 3-20             132,096\n",
      "├─Linear: 1-7                            5,130\n",
      "=================================================================\n",
      "Total params: 4,903,242\n",
      "Trainable params: 4,903,242\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Conv2d: 1-1                            1,728\n",
      "├─BatchNorm2d: 1-2                       128\n",
      "├─Sequential: 1-3                        --\n",
      "|    └─BasicBlock: 2-1                   --\n",
      "|    |    └─Conv2d: 3-1                  36,864\n",
      "|    |    └─BatchNorm2d: 3-2             128\n",
      "|    |    └─Conv2d: 3-3                  36,864\n",
      "|    |    └─BatchNorm2d: 3-4             128\n",
      "|    |    └─Sequential: 3-5              --\n",
      "├─Sequential: 1-4                        --\n",
      "|    └─BasicBlock: 2-2                   --\n",
      "|    |    └─Conv2d: 3-6                  73,728\n",
      "|    |    └─BatchNorm2d: 3-7             256\n",
      "|    |    └─Conv2d: 3-8                  147,456\n",
      "|    |    └─BatchNorm2d: 3-9             256\n",
      "|    |    └─Sequential: 3-10             8,448\n",
      "├─Sequential: 1-5                        --\n",
      "|    └─BasicBlock: 2-3                   --\n",
      "|    |    └─Conv2d: 3-11                 294,912\n",
      "|    |    └─BatchNorm2d: 3-12            512\n",
      "|    |    └─Conv2d: 3-13                 589,824\n",
      "|    |    └─BatchNorm2d: 3-14            512\n",
      "|    |    └─Sequential: 3-15             33,280\n",
      "├─Sequential: 1-6                        --\n",
      "|    └─BasicBlock: 2-4                   --\n",
      "|    |    └─Conv2d: 3-16                 1,179,648\n",
      "|    |    └─BatchNorm2d: 3-17            1,024\n",
      "|    |    └─Conv2d: 3-18                 2,359,296\n",
      "|    |    └─BatchNorm2d: 3-19            1,024\n",
      "|    |    └─Sequential: 3-20             132,096\n",
      "├─Linear: 1-7                            5,130\n",
      "=================================================================\n",
      "Total params: 4,903,242\n",
      "Trainable params: 4,903,242\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "# Model Configuration :\n",
    "\n",
    "layers=[1, 1, 1, 1]\n",
    "kernel_size = 1\n",
    "pool_size = 4\n",
    "model = ResNet(BasicBlock, layers)\n",
    "\n",
    "print(summary(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d2915e-4d45-491a-8c9b-f977d534fb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "94.5%IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "\n",
      "Epoch: 0\n",
      "Train Loss: 1.165 | Train Acc: 45.612% (22806/50000)\n",
      "Test Loss: 1.062 | Test Acc: 52.560% (5256/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 1\n",
      "Train Loss: 0.858 | Train Acc: 60.602% (30301/50000)\n",
      "Test Loss: 0.891 | Test Acc: 61.490% (6149/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 2\n",
      "Train Loss: 0.727 | Train Acc: 66.906% (33453/50000)\n",
      "Test Loss: 0.859 | Test Acc: 64.050% (6405/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 3\n",
      "Train Loss: 0.637 | Train Acc: 71.306% (35653/50000)\n",
      "Test Loss: 0.916 | Test Acc: 65.530% (6553/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 4\n",
      "Train Loss: 0.567 | Train Acc: 74.378% (37189/50000)\n",
      "Test Loss: 0.502 | Test Acc: 78.160% (7816/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 5\n",
      "Train Loss: 0.515 | Train Acc: 77.156% (38578/50000)\n",
      "Test Loss: 0.529 | Test Acc: 76.990% (7699/10000)\n",
      "\n",
      "Epoch: 6\n",
      "Train Loss: 0.476 | Train Acc: 78.902% (39451/50000)\n",
      "Test Loss: 0.557 | Test Acc: 76.660% (7666/10000)\n",
      "\n",
      "Epoch: 7\n",
      "Train Loss: 0.444 | Train Acc: 80.126% (40063/50000)\n",
      "Test Loss: 0.496 | Test Acc: 78.930% (7893/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 8\n",
      "Train Loss: 0.417 | Train Acc: 81.366% (40683/50000)\n",
      "Test Loss: 0.585 | Test Acc: 75.530% (7553/10000)\n",
      "\n",
      "Epoch: 9\n",
      "Train Loss: 0.393 | Train Acc: 82.352% (41176/50000)\n",
      "Test Loss: 0.410 | Test Acc: 82.510% (8251/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 10\n",
      "Train Loss: 0.373 | Train Acc: 83.234% (41617/50000)\n",
      "Test Loss: 0.385 | Test Acc: 83.260% (8326/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 11\n",
      "Train Loss: 0.354 | Train Acc: 84.426% (42213/50000)\n",
      "Test Loss: 0.423 | Test Acc: 82.210% (8221/10000)\n",
      "\n",
      "Epoch: 12\n",
      "Train Loss: 0.340 | Train Acc: 84.904% (42452/50000)\n",
      "Test Loss: 0.410 | Test Acc: 83.050% (8305/10000)\n",
      "\n",
      "Epoch: 13\n",
      "Train Loss: 0.322 | Train Acc: 85.700% (42850/50000)\n",
      "Test Loss: 0.558 | Test Acc: 78.160% (7816/10000)\n",
      "\n",
      "Epoch: 14\n",
      "Train Loss: 0.312 | Train Acc: 86.022% (43011/50000)\n",
      "Test Loss: 0.391 | Test Acc: 83.410% (8341/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 15\n",
      "Train Loss: 0.300 | Train Acc: 86.724% (43362/50000)\n",
      "Test Loss: 0.365 | Test Acc: 84.430% (8443/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 16\n",
      "Train Loss: 0.288 | Train Acc: 87.222% (43611/50000)\n",
      "Test Loss: 0.426 | Test Acc: 83.270% (8327/10000)\n",
      "\n",
      "Epoch: 17\n",
      "Train Loss: 0.277 | Train Acc: 87.542% (43771/50000)\n",
      "Test Loss: 0.439 | Test Acc: 82.590% (8259/10000)\n",
      "\n",
      "Epoch: 18\n",
      "Train Loss: 0.267 | Train Acc: 88.152% (44076/50000)\n",
      "Test Loss: 0.441 | Test Acc: 82.180% (8218/10000)\n",
      "\n",
      "Epoch: 19\n",
      "Train Loss: 0.257 | Train Acc: 88.404% (44202/50000)\n",
      "Test Loss: 0.298 | Test Acc: 87.690% (8769/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 20\n",
      "Train Loss: 0.251 | Train Acc: 88.966% (44483/50000)\n",
      "Test Loss: 0.328 | Test Acc: 86.900% (8690/10000)\n",
      "\n",
      "Epoch: 21\n",
      "Train Loss: 0.243 | Train Acc: 89.220% (44610/50000)\n",
      "Test Loss: 0.353 | Test Acc: 85.910% (8591/10000)\n",
      "\n",
      "Epoch: 22\n",
      "Train Loss: 0.235 | Train Acc: 89.444% (44722/50000)\n",
      "Test Loss: 0.442 | Test Acc: 82.810% (8281/10000)\n",
      "\n",
      "Epoch: 23\n",
      "Train Loss: 0.226 | Train Acc: 90.076% (45038/50000)\n",
      "Test Loss: 0.389 | Test Acc: 84.200% (8420/10000)\n",
      "\n",
      "Epoch: 24\n",
      "Train Loss: 0.219 | Train Acc: 90.146% (45073/50000)\n",
      "Test Loss: 0.293 | Test Acc: 88.130% (8813/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 25\n",
      "Train Loss: 0.216 | Train Acc: 90.406% (45203/50000)\n",
      "Test Loss: 0.290 | Test Acc: 87.940% (8794/10000)\n",
      "\n",
      "Epoch: 26\n",
      "Train Loss: 0.206 | Train Acc: 90.822% (45411/50000)\n",
      "Test Loss: 0.422 | Test Acc: 84.650% (8465/10000)\n",
      "\n",
      "Epoch: 27\n",
      "Train Loss: 0.201 | Train Acc: 91.086% (45543/50000)\n",
      "Test Loss: 0.345 | Test Acc: 86.110% (8611/10000)\n",
      "\n",
      "Epoch: 28\n",
      "Train Loss: 0.195 | Train Acc: 91.400% (45700/50000)\n",
      "Test Loss: 0.313 | Test Acc: 87.530% (8753/10000)\n",
      "\n",
      "Epoch: 29\n",
      "Train Loss: 0.188 | Train Acc: 91.450% (45725/50000)\n",
      "Test Loss: 0.292 | Test Acc: 88.040% (8804/10000)\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    acc = 100.*correct/total\n",
    "    loss = 100.*train_loss/total\n",
    "    print('Train Loss: %.3f | Train Acc: %.3f%% (%d/%d)'\n",
    "                     % (loss, acc, correct, total))\n",
    "    model_results[str(epoch)] =  {\"train\" : {\"acc\" : acc,\"loss\" : loss},\"test\" : {}}\n",
    "\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            # print(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "            #              % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    loss = 100.*test_loss/total\n",
    "    model_results[str(epoch)]['test']  = {\"acc\" : acc,\"loss\" : loss}\n",
    "    print('Test Loss: %.3f | Test Acc: %.3f%% (%d/%d)'\n",
    "                     % (loss, acc, correct, total))\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, './checkpoint/ckpt.pth')\n",
    "        best_acc = acc\n",
    "        \n",
    "#Model Parameters\n",
    "\n",
    "batch_size = 128\n",
    "lr = 1e-2\n",
    "optim_param = {'la_steps':5,\n",
    "               'la_alpha':0.5\n",
    "              }\n",
    "resume = False \n",
    "model_results = {}\n",
    "\n",
    "#Load model\n",
    "        \n",
    "net = model\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "\n",
    "if resume:\n",
    "    # Load checkpoint.\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
    "    checkpoint = torch.load('./checkpoint/ckpt.pth')\n",
    "    net.load_state_dict(checkpoint['net'])\n",
    "    best_acc = checkpoint['acc']\n",
    "    start_epoch = checkpoint['epoch']\n",
    "\n",
    "# Data\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    Cutout(n_holes=1, length=8)\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "base_optim = optim.SGD(net.parameters(), lr=lr,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "Q = math.floor(len(trainset)/batch_size)\n",
    "optimizer = Lookahead(base_optim, **optim_param)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=Q)\n",
    "\n",
    "epochs = 30\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+epochs):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6162c83a-02d5-415d-a59d-f7115f0c6d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('./checkpoint/ckpt.pth')\n",
    "net.load_state_dict(checkpoint['net'])\n",
    "best_acc = checkpoint['acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f88609c-f8ea-4985-a444-b73be5abee9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.13"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d8d025-50ca-48a0-9a53-5a33126d5f32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
